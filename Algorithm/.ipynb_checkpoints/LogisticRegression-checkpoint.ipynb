{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression implementation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is the first of its kind classification technique that can easily classify into multiple categories and that too by usig the same linear model techniques. After getting the output using the linear model, we run it through a sigmoid function and get are class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Structure\n",
    "\n",
    "Assume 0's to be weights for the linear model.\n",
    "\n",
    "for each iteration:\n",
    "    \n",
    "    find the output of the linear model using existing weights\n",
    "    find the delta wrt the true values.\n",
    "    update the weights using a learning rate. \n",
    "    \n",
    "for predictions:\n",
    "\n",
    "    simply use sigmoid of the output using the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, x, y, n_iter=1500, lr=0.01):\n",
    "        self.w = np.zeros((x.shape[1], 1))\n",
    "        self.lr = lr/x.shape[0]\n",
    "        self.n_iter = n_iter\n",
    "        self.x, self.y = x, y\n",
    "\n",
    "    def fit(self):\n",
    "            for i in range(self.n_iter):\n",
    "                predictions = self.predict(self.x)\n",
    "                delta = self.y - predictions\n",
    "                self.w += (self.lr * (self.x.T @ delta))\n",
    "        \n",
    "    def predict(self, x):\n",
    "            l = x @ self.w\n",
    "            return np.round(sigmoid(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "d = data.data\n",
    "X_train = pd.DataFrame(d, columns=data.feature_names)\n",
    "y_train = data.target[:, None]\n",
    "X_train = (X_train - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939855187357962"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_lr = LogR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lr.fit(X_train, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876977152899824"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lr.score(X_train, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our overall training set accuracy is around 93% and the sklearn model gives around 98% accuracy. We are close enough to say that we have achieved nirvana for now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression python implementation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is the most basic and most used technique when it comes to predicting using regression analysis. In large parts of corporate business analytics, regression has been the end goal. It is very important to understand this and move forward without getting stuck. By far the easiest way is to experiment and build things. This notebook starts out with basic code to clean things and put them together. This comes from numpy and pandas but from there we pick up the bricks and build this house. \n",
    "\n",
    "Source: https://www.youtube.com/watch?v=4b4MUYve_U8&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Structure\n",
    "\n",
    "Assume sample weights to be zero in the beginning. We assume that the input is normalised and contains values between a small range(0,1). This helps the algorithm to train faster and easily. \n",
    "\n",
    "We use back propagation and learning to change our sample weights. \n",
    "\n",
    "We also add an additional column in the training data to use this for intercept calculation.\n",
    "\n",
    "The end equation is:\n",
    "    \n",
    "    for each iteration:\n",
    "        \n",
    "        prediction = [weights] @ [Input dataframe]\n",
    "        weights = weights - (predictions - true output) * learning rate @ input data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel():\n",
    "    def __init__(self, X, y, n_iter=1000, learning_rate=0.01):\n",
    "        self.w = np.zeros((X.shape[1], 1))\n",
    "        self.learning_rate = learning_rate/X.shape[0]\n",
    "        self.n_iter = n_iter\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def fit(self):\n",
    "        for i in range(self.n_iter):\n",
    "            predictions = self.X @ self.w - self.y\n",
    "            delta = self.learning_rate*(self.X.T @ (predictions))\n",
    "            self.w -= delta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X_train = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y_train = dataset.target[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['DIS', 'INDUS', 'LSTAT', 'NOX', 'RAD', 'TAX', 'ZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train-X_train.mean())/X_train.std()\n",
    "X_train['intercept'] = np.ones(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearModel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6368893071818802"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lin = LinearRegression()\n",
    "sklearn_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6368894212487402"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_lin.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook created a Linear Regression model from scratch. Its fast but slightly slower than the sklearn model but it is almost eqaully good predictive of the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
